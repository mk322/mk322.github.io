---
permalink: /
title: "Publications"
excerpt: "pub"
author_profile: true
redirect_from: 
  - /publication/
  - /publication.html
---
Hello! I'm a passionate researcher in the field of Natural Language Processing (NLP), currently working as a Research Assistant under the supervision of [Dr. Xiao-Yang Liu](https://scholar.google.com/citations?user=C83b8ncAAAAJ&hl=en) at Columbia University. I earned my Bachelor of Science degree from the prestigious [Paul G. Allen School of Computer Science at the University of Washington, Seattle](https://www.cs.washington.edu/). During my undergraduate time, I am forunated to to work closely with [Prof. Luke Zettlemoyer](https://www.cs.washington.edu/people/faculty/lsz) and [Terra Blevins](https://blvns.github.io/), who provided invaluable mentorship and guidance in my early research endeavors. After undergraduate graduation, I ventured into a research internship with [Dr. Huaxiu Yao](https://www.huaxiuyao.io/) at the University of North Carolina (UNC).

I am actively applying for graduate programs in NLP/CS and am also interested in securing a summer research internship in the industry. If you know of any relevant openings or could provide an introduction, I would deeply appreciate your support.

Research Interests
======
My primary research interests lie at the challenges and deficiency of Large Language Models, focusing on:

- Trustworthy NLP, Hallucination, Factuality: I am fascinated by the challenges of ensuring the reliability and truthfulness of NLP outputs. My work aims to mitigate issues like hallucination in generated text and enhance the factuality of LLMs.

- Multilingual NLP: With the digital world erasing geographical boundaries, I believe in the power of multilingual NLP to bridge communication gaps. I'm working on models that can understand and process multiple languages, bringing down linguistic barriers in information access.

- Reasoning ability of LLMs: My research also encompasses enhancing the reasoning capabilities of large language models. The goal is to develop models that not only "understand" or "generate" text but can "reason", "infer", and make logical conclusions, thereby simulating a more human-like understanding of language and context.

As I continue this exciting journey in NLP, I am always eager to collaborate, share insights, and learn from others in this dynamic field. Feel free to reach out to me for collaborations, discussions, or even a casual chat about the future of NLP!
